# Module 14: Key Terms Glossary

[← Previous: The KM–AI Connection](13-km-ai-connection.md) | [Back to Learning Path](../README.md)

---

Quick reference for conversations, interviews, and reading. Terms are grouped by category.

---

## Core Concepts

**LLM (Large Language Model)** — A neural network trained on massive text data to generate human-like language. Examples: GPT-4, Claude, Gemini, Llama.

**Token** — The basic unit LLMs process. Roughly ¾ of a word. Everything (cost, limits, speed) is measured in tokens.

**Context Window** — The total amount of text an LLM can "see" at once. Its working memory. Claude: ~200K tokens. GPT-4 Turbo: ~128K tokens.

**Parameter** — A single learned weight in the neural network. More parameters = more capacity to capture patterns. GPT-3 has 175 billion parameters.

**Inference** — The process of running a trained model to generate output. Each API call is an inference. Cost is per-token.

**Hallucination** — When an LLM generates confident but factually incorrect text. Structural to the architecture, not a fixable bug.

---

## Architecture

**Transformer** — The neural network architecture underlying all modern LLMs. Key innovation: self-attention. From the 2017 paper "Attention Is All You Need."

**Attention (Self-Attention)** — The mechanism that lets a model weigh how much every word should "attend to" every other word, enabling understanding of long-range relationships in text.

**Multi-Head Attention** — Running multiple attention processes in parallel, each learning different types of relationships (grammar, meaning, position, etc.).

**Encoder** — Transformer component that processes input and creates internal representations. Used in models designed for understanding (e.g., BERT).

**Decoder** — Transformer component that generates output one token at a time. Used in GPT-style models designed for generation.

**Neural Network** — A computing system of interconnected mathematical functions (neurons) organized in layers. Adjustable weights are tuned during training.

---

## Training & Alignment

**Pre-training** — The first stage: model reads trillions of tokens and learns language patterns. Produces a base model (powerful autocomplete, not yet helpful).

**Fine-tuning (SFT)** — Training on curated examples of helpful conversations. Turns the base model into an assistant that follows instructions.

**RLHF (Reinforcement Learning from Human Feedback)** — Humans rate model outputs; a reward model learns from these ratings; the main model is trained to maximize the reward. Makes the model aligned with human values.

**Constitutional AI (CAI)** — Anthropic's approach: model is trained against a set of principles, critiquing and revising its own outputs. Used in Claude.

**Reward Model** — A separate model trained on human preferences that provides a "score" signal for RLHF training.

**Distillation** — Training a smaller, cheaper model to mimic a larger model's behavior. Enables deployment at scale.

**Synthetic Data** — Training data generated by AI models rather than humans. Useful for scale but risks amplifying biases.

**Base Model** — The model after pre-training but before fine-tuning. Can complete text but isn't conversational or helpful.

---

## Retrieval & Knowledge

**RAG (Retrieval-Augmented Generation)** — A pattern that retrieves relevant documents from a knowledge base and puts them in the LLM's context window before generating an answer. The dominant enterprise AI architecture.

**Embedding** — A mathematical representation (vector) of text that captures its semantic meaning. Similar meanings = close vectors.

**Vector** — A list of numbers representing a point in high-dimensional space. Embeddings are vectors.

**Vector Database** — A database optimized for storing and searching vectors. Examples: Pinecone, Weaviate, Chroma, Azure AI Search.

**Semantic Search** — Searching by meaning rather than keywords, powered by embeddings. "Flat tire" matches "punctured tyre."

**Chunking** — Splitting large documents into smaller pieces for embedding and retrieval. Strategy (fixed-size, semantic, hierarchical) impacts quality.

**Re-ranking** — A secondary scoring step after initial retrieval, using a more sophisticated model to sort results by actual relevance.

**Hybrid Search** — Combining vector/semantic search with traditional keyword search for better retrieval results.

**Grounding** — Ensuring AI outputs are tied to verified source material rather than the model's general training. Core enterprise AI challenge.

**Knowledge Graph** — A structured representation of entities and their relationships. Enables relationship-based reasoning beyond text similarity.

---

## Prompting

**Prompt** — The input given to an LLM: instructions, context, and the user's query combined.

**System Prompt** — Hidden instructions that set the AI's overall behavior, tone, and constraints. The user doesn't see these.

**Few-Shot Prompting** — Providing examples in the prompt to teach the model a pattern. Zero-shot = no examples.

**Chain of Thought (CoT)** — Asking the model to reason step by step before answering. Improves accuracy on complex tasks.

**Temperature** — A parameter controlling randomness in token selection. Low = deterministic and focused. High = creative and varied.

**Top-k / Top-p Sampling** — Methods for limiting which tokens the model considers. Top-k: consider the k most likely. Top-p: consider tokens until cumulative probability reaches p.

**Prompt Template** — A standardized prompt structure with variables that get filled in per query. The enterprise evolution of prompt engineering.

---

## Agents & Tools

**Agent** — An AI system that doesn't just answer questions but takes actions: using tools, making decisions, and executing multi-step workflows in a loop.

**Tool Use (Function Calling)** — The mechanism that lets an LLM request the execution of external tools (search, code, APIs).

**MCP (Model Context Protocol)** — An open standard (by Anthropic) for connecting AI models to tools and data sources. Universal adapter for AI-tool integration.

**Orchestration** — Coordinating multiple AI components, tools, and steps in a workflow. The management layer of agentic systems.

**Human-in-the-Loop** — AI systems that involve human review or approval at critical decision points. Essential for trust in enterprise agents.

**Multi-Agent System** — Multiple specialized AI models working together, each handling different aspects of a task.

---

## Multimodal

**Multimodal** — AI that processes and/or generates multiple types of data: text, images, audio, video, code.

**Vision Encoder** — The component that converts images into tokens an LLM can process alongside text.

**Diffusion Model** — The architecture behind image generation (DALL-E, Midjourney, Stable Diffusion). Starts with noise, gradually refines into an image.

**Speech-to-Text (STT)** — Converting spoken audio to written text. Example: OpenAI's Whisper.

**Text-to-Speech (TTS)** — Generating spoken audio from written text.

---

## Enterprise & Strategy

**AI Governance** — Policies and frameworks for responsible AI deployment: data access, output review, bias monitoring, compliance.

**Digital Maturity** — An organization's readiness to effectively adopt digital technologies, including AI. Often assessed across technology, process, people, and culture dimensions.

**Build vs Buy** — The strategic decision between using off-the-shelf AI products (Copilot, Einstein) or building custom solutions.

**Open Model** — An LLM with publicly available weights that can be downloaded, run, and modified. Examples: Llama, Mistral.

**Closed Model** — An LLM accessible only through an API or interface, with proprietary architecture. Examples: GPT-4, Claude.

**AI-Ready Content** — Content structured, maintained, and governed to be effectively consumed by AI systems — well-tagged, current, concise, and semantically clear.

**Content Freshness** — The percentage of content in a knowledge base that is current and up to date. Directly impacts AI answer accuracy.

---

## Acronym Quick Reference

| Acronym | Full Form |
|---|---|
| LLM | Large Language Model |
| RAG | Retrieval-Augmented Generation |
| RLHF | Reinforcement Learning from Human Feedback |
| CAI | Constitutional AI |
| SFT | Supervised Fine-Tuning |
| MCP | Model Context Protocol |
| MoE | Mixture of Experts |
| LoRA | Low-Rank Adaptation |
| QLoRA | Quantized Low-Rank Adaptation |
| STT | Speech-to-Text |
| TTS | Text-to-Speech |
| BPE | Byte Pair Encoding |
| CoT | Chain of Thought |
| API | Application Programming Interface |
| GPU | Graphics Processing Unit (the hardware that trains/runs AI) |
| NLP | Natural Language Processing |
| XAI | Explainable AI |
| GAN | Generative Adversarial Network |
| CNN | Convolutional Neural Network |
| RNN | Recurrent Neural Network |
| LSTM | Long Short-Term Memory |

---

## Additional Terms (from Nate's A-to-Z Guide)

**Latent Space** — The mathematical landscape where all possible meanings exist as coordinates. The model navigates this space to connect your question to its answer. Hallucinations happen in sparse, unexplored regions.

**Positional Encoding** — Mathematical patterns (sine/cosine waves) added to tokens to preserve word order. Without it, "dog bites man" = "man bites dog."

**Residual Stream** — The highway that carries information through transformer layers. Each layer adds insights without erasing previous ones.

**Feature Superposition** — Single neurons encode multiple overlapping concepts. Explains weird associations and why AI behavior can be unpredictable.

**Catastrophic Forgetting** — New training can overwrite old knowledge. Why you can't just "teach" a deployed model new things without special techniques.

**Emergent Abilities** — Sudden capabilities that appear at certain scale thresholds. Not gradual improvement — more like phase transitions.

**LoRA (Low-Rank Adaptation)** — Small adapter layers that specialize a frozen base model cheaply. Enables brand-voice fine-tuning with ~50-100 examples on consumer hardware.

**QLoRA** — LoRA combined with quantization. Makes fine-tuning possible on consumer GPUs.

**Quantization** — Reducing number precision in model weights (32-bit → 8-bit) to shrink models 4-8x while retaining ~95% performance. Enables on-device AI.

**Speculative Decoding** — A small fast model drafts several tokens; a large model verifies them in parallel. 3-4x faster generation. Why AI "bursts" words.

**Prompt Injection** — Hidden commands in text that hijack AI behavior. The #1 AI security vulnerability. Coined by Simon Willison.

**Beam Search** — Exploring multiple output paths in parallel and selecting the best overall sequence. Best for translation and formal documents.

**Nucleus Sampling (Top-p)** — Including tokens until cumulative probability reaches threshold P. Adapts automatically to model confidence. Default: p≈0.9.

---

## Terms from the D4B Course

**Expert Systems** — 1980s AI approach encoding domain expertise in decision rules. The predecessor to modern AI knowledge systems.

**AI Winters** — Periods of reduced funding and interest in AI (1970s, late 1980s-90s) following unmet promises.

**Neuro-symbolic AI** — Combining neural networks (learning) with symbolic reasoning (logic). A current research frontier.

**Explainable AI (XAI)** — Techniques for making AI decisions transparent and interpretable. Required by the EU AI Act for high-risk systems.

**Edge AI** — Running AI models on local devices (phones, laptops, IoT) rather than cloud servers. Enabled by quantization.

**EU AI Act** — World's first comprehensive AI regulation. Classifies AI systems by risk level with corresponding requirements.

---

[← Previous: The KM–AI Connection](13-km-ai-connection.md) | [Back to Learning Path](../README.md)
